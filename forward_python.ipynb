{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from scipy.special import expit as sigmoid\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters for a small LSTM network\n",
    "input_size  = 1 # size of one 'event', or sample, in our batch of data\n",
    "hidden_dim  = 3 # 30 cells in the LSTM layer\n",
    "output_size = 1 # desired model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3581,  0.1449, -0.1517, -0.0627,  0.2185,  0.3742,  0.1810, -0.3759,\n",
      "          0.5075, -0.0862,  0.4901,  0.4955]])\n",
      "tensor([-0.3353, -0.3428, -0.5422, -0.1341, -0.0048,  0.2355,  0.2891, -0.3969,\n",
      "         0.2711,  0.1751, -0.0789, -0.3125])\n",
      "tensor([[-0.3813, -0.0860,  0.4179,  0.5138, -0.4246, -0.0035,  0.1918, -0.5070,\n",
      "          0.4756, -0.2009, -0.3760,  0.2356],\n",
      "        [-0.0175,  0.3113,  0.3616, -0.3160,  0.5756, -0.4261,  0.0499, -0.1637,\n",
      "          0.1121,  0.2702, -0.4745, -0.1081],\n",
      "        [ 0.2550,  0.0359,  0.5455, -0.1759, -0.0060, -0.3326, -0.4534, -0.2762,\n",
      "         -0.0910,  0.5070, -0.4937,  0.1096]])\n",
      "tensor([-0.2699, -0.4251, -0.2621,  0.0815,  0.3582, -0.4591,  0.4775, -0.5156,\n",
      "         0.5231, -0.4899,  0.2584, -0.3921])\n",
      "tensor([[ 0.3681,  0.4744, -0.0601]])\n",
      "tensor([-0.2165])\n"
     ]
    }
   ],
   "source": [
    "#Initialize an PyTorch LSTM for comparison to our Numpy LSTM\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers=1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_dim=hidden_dim\n",
    "        self.lstm = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True) # LSTM Layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_size) # fully-connected layer\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        batch_size = 1\n",
    "        # get LSTM outputs\n",
    "        lstm_output, (h,c) = self.lstm(x, hidden)\n",
    "        # shape output to be (batch_size*seq_length, hidden_dim)\n",
    "        lstm_output = lstm_output.view(-1, self.hidden_dim)  \n",
    "        # get final output \n",
    "        model_output = self.fc(lstm_output)\n",
    "        \n",
    "        return model_output, (h,c)\n",
    "      \n",
    "torch.manual_seed(42069)\n",
    "torch_lstm = LSTM(input_size = input_size, \n",
    "                 hidden_dim = hidden_dim,\n",
    "                 output_size = output_size,\n",
    "                 )\n",
    "\n",
    "state = torch_lstm.state_dict()\n",
    "# print(state)\n",
    "print(np.transpose(state['lstm.weight_ih_l0']))\n",
    "print(np.transpose(state['lstm.bias_ih_l0']))\n",
    "print(np.transpose(state['lstm.weight_hh_l0']))\n",
    "print(np.transpose(state['lstm.bias_hh_l0']))\n",
    "print(state['fc.weight'])\n",
    "print(state['fc.bias'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0517], [0.3158], [-0.432], [0.2567]]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------\n",
    "#Simple Time Series Data\n",
    "# data = np.random.rand(2, input_size)\n",
    "data = [[0.0517], [0.3158], [-0.432], [0.2567]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PyTorch LSTM Output:\n",
      "tensor([[-0.2451],\n",
      "        [-0.2719],\n",
      "        [-0.2536],\n",
      "        [-0.2818]], grad_fn=<AddmmBackward>)\n",
      "\n",
      " ----------------------------------------\n",
      "Torch Hidden State: tensor([[[ 0.1665, -0.2494,  0.1377]]], grad_fn=<StackBackward>)\n",
      "Torch Cell State: tensor([[[ 0.4326, -0.4673,  0.3855]]], grad_fn=<StackBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#PyTorch expects an extra dimension for batch size:\n",
    "torch_batch = torch.Tensor(data).unsqueeze(0) \n",
    "torch_output, (torch_hidden, torch_cell) = torch_lstm(torch_batch, None)\n",
    "\n",
    "print('\\nPyTorch LSTM Output:')\n",
    "print(torch_output)\n",
    "print('\\n','-'*40)\n",
    "print(f'Torch Hidden State: {torch_hidden}')\n",
    "print(f'Torch Cell State: {torch_cell}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forget_gate(x, h, Weights_hf, Bias_hf, Weights_xf, Bias_xf, prev_cell_state):\n",
    "    forget_hidden  = np.dot(Weights_hf, h) + Bias_hf\n",
    "    forget_eventx  = np.dot(Weights_xf, x) + Bias_xf\n",
    "    print('f_input: ', forget_hidden + forget_eventx)\n",
    "    result = np.multiply( sigmoid(forget_hidden + forget_eventx), prev_cell_state )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_gate(x, h, Weights_hi, Bias_hi, Weights_xi, Bias_xi, Weights_hl, Bias_hl, Weights_xl, Bias_xl):\n",
    "    ignore_hidden  = np.dot(Weights_hi, h) + Bias_hi\n",
    "    ignore_eventx  = np.dot(Weights_xi, x) + Bias_xi\n",
    "    learn_hidden   = np.dot(Weights_hl, h) + Bias_hl\n",
    "    learn_eventx   = np.dot(Weights_xl, x) + Bias_xl\n",
    "    print('i_input: ', ignore_hidden + ignore_eventx)\n",
    "    print('c_input: ', learn_hidden + learn_eventx)\n",
    "    return np.multiply( sigmoid(ignore_eventx + ignore_hidden), np.tanh(learn_eventx + learn_hidden) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_state(forget_gate_output, input_gate_output):\n",
    "    return forget_gate_output + input_gate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_gate(x, h, Weights_ho, Bias_ho, Weights_xo, Bias_xo, cell_state):\n",
    "    out_hidden = np.dot(Weights_ho, h) + Bias_ho\n",
    "    out_eventx = np.dot(Weights_xo, x) + Bias_xo\n",
    "    print('o_input: ', out_hidden + out_eventx)\n",
    "    return np.multiply( sigmoid(out_eventx + out_hidden), np.tanh(cell_state) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_output(lstm_output, fc_Weight, fc_Bias):\n",
    "  ## Takes the LSTM output and transforms it to our desired output size using a final, fully connected layer\n",
    "  return np.dot(fc_Weight, lstm_output) + fc_Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Event (x) Weights and Biases for all gates\n",
    "Weights_xi = state['lstm.weight_ih_l0'][0:hidden_dim].numpy()  # shape  [h, x]\n",
    "Weights_xf = state['lstm.weight_ih_l0'][hidden_dim:hidden_dim*2].numpy()  # shape  [h, x]\n",
    "Weights_xl = state['lstm.weight_ih_l0'][hidden_dim*2:hidden_dim*3].numpy()  # shape  [h, x]\n",
    "Weights_xo = state['lstm.weight_ih_l0'][hidden_dim*3:hidden_dim*4].numpy() # shape  [h, x]\n",
    "\n",
    "Bias_xi = state['lstm.bias_ih_l0'][0:hidden_dim].numpy()  #shape is [h, 1]\n",
    "Bias_xf = state['lstm.bias_ih_l0'][hidden_dim:hidden_dim*2].numpy()  #shape is [h, 1]\n",
    "Bias_xl = state['lstm.bias_ih_l0'][hidden_dim*2:hidden_dim*3].numpy()  #shape is [h, 1]\n",
    "Bias_xo = state['lstm.bias_ih_l0'][hidden_dim*3:hidden_dim*4].numpy() #shape is [h, 1]\n",
    "\n",
    "#Hidden state (h) Weights and Biases for all gates\n",
    "Weights_hi = state['lstm.weight_hh_l0'][0:hidden_dim].numpy()  #shape is [h, h]\n",
    "Weights_hf = state['lstm.weight_hh_l0'][hidden_dim:hidden_dim*2].numpy()  #shape is [h, h]\n",
    "Weights_hl = state['lstm.weight_hh_l0'][hidden_dim*2:hidden_dim*3].numpy()  #shape is [h, h]\n",
    "Weights_ho = state['lstm.weight_hh_l0'][hidden_dim*3:hidden_dim*4].numpy() #shape is [h, h]\n",
    "\n",
    "Bias_hi = state['lstm.bias_hh_l0'][0:hidden_dim].numpy()  #shape is [h, 1]\n",
    "Bias_hf = state['lstm.bias_hh_l0'][hidden_dim:hidden_dim*2].numpy()  #shape is [h, 1]\n",
    "Bias_hl = state['lstm.bias_hh_l0'][hidden_dim*2:hidden_dim*3].numpy()  #shape is [h, 1]\n",
    "Bias_ho = state['lstm.bias_hh_l0'][hidden_dim*3:hidden_dim*4].numpy() #shape is [h, 1]\n",
    "\n",
    "# Final, fully connected layer Weights and Bias\n",
    "fc_Weight = state['fc.weight'][0].numpy() #shape is [h, output_size]\n",
    "fc_Bias = state['fc.bias'][0].numpy() #shape is [,output_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize cell and hidden states with zeroes\n",
    "h = np.zeros(hidden_dim)\n",
    "c = np.zeros(hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy LSTM Output:\n",
      "\n",
      " input: [0.0517]\n",
      "f_input:  [-0.05589518  0.36465428 -0.20423766]\n",
      "f: [0. 0. 0.]\n",
      "i_input:  [-0.58665261 -0.76035089 -0.81214845]\n",
      "c_input:  [ 0.77588532 -0.93191654  0.82045399]\n",
      "i: [ 0.23243316 -0.23302962  0.20761461]\n",
      "c: [ 0.23243316 -0.23302962  0.20761461]\n",
      "o_input:  [-0.3193262   0.20481827 -0.67898336]\n",
      "h: [ 0.09609288 -0.12613059  0.06887314]\n",
      "-0.245144551475458\n",
      "\n",
      " input: [0.3158]\n",
      "f_input:  [ 0.00467114  0.30853368 -0.0749157 ]\n",
      "f: [ 0.11648801 -0.13434794  0.09992072]\n",
      "i_input:  [-0.5089514  -0.76714461 -0.82009158]\n",
      "c_input:  [ 0.80458947 -1.07828439  0.97977924]\n",
      "i: [ 0.25026591 -0.25131913  0.23021632]\n",
      "c: [ 0.36675392 -0.38566707  0.33013705]\n",
      "o_input:  [-0.3605575   0.32396719 -0.50430056]\n",
      "h: [ 0.14426071 -0.21332583  0.11997917]\n",
      "-0.2718528413537026\n",
      "\n",
      " input: [-0.432]\n",
      "f_input:  [ 0.09485281  0.07422218 -0.33471362]\n",
      "f: [ 0.19206735 -0.19998651  0.13769824]\n",
      "i_input:  [-0.78056683 -0.90494716 -0.69014801]\n",
      "c_input:  [ 0.65097977 -0.8214569   0.60878946]\n",
      "i: [ 0.17982453 -0.19467187  0.18145373]\n",
      "c: [ 0.37189188 -0.39465838  0.31915197]\n",
      "o_input:  [-0.30344201 -0.04448631 -0.84843005]\n",
      "h: [ 0.15104839 -0.1835106   0.09254859]\n",
      "-0.253560091273079\n",
      "\n",
      " input: [0.2567]\n",
      "f_input:  [ 0.05058043  0.23911833 -0.08064193]\n",
      "f: [ 0.19064755 -0.22080993  0.15314521]\n",
      "i_input:  [-0.54403351 -0.79744787 -0.79598847]\n",
      "c_input:  [ 0.79083783 -1.08107861  0.96734274]\n",
      "i: [ 0.24197479 -0.24646932  0.23239665]\n",
      "c: [ 0.43262234 -0.46727925  0.38554186]\n",
      "o_input:  [-0.37000849  0.28987983 -0.51183405]\n",
      "h: [ 0.16648392 -0.24937656  0.13772961]\n",
      "-0.28184245992034257\n",
      "np Hidden State: [ 0.16648392 -0.24937656  0.13772961]\n",
      "np Cell State: [ 0.43262234 -0.46727925  0.38554186]\n"
     ]
    }
   ],
   "source": [
    "#Loop through a batch of data, updating the hidden and cell states each time\n",
    "print('NumPy LSTM Output:')\n",
    "i = 0\n",
    "for eventx in data:\n",
    "    print('\\n', 'input:', eventx)\n",
    "    \n",
    "    f = forget_gate(eventx, h, Weights_hf, Bias_hf, Weights_xf, Bias_xf, c)\n",
    "    print('f:', f)\n",
    "    \n",
    "    i = input_gate(eventx, h, Weights_hi, Bias_hi, Weights_xi, Bias_xi, Weights_hl, Bias_hl, Weights_xl, Bias_xl)\n",
    "    print('i:', i)\n",
    "\n",
    "    c = cell_state(f,i)\n",
    "    print('c:', c)\n",
    "\n",
    "    h = output_gate(eventx, h, Weights_ho, Bias_ho, Weights_xo, Bias_xo, c)\n",
    "    print('h:', h)\n",
    "    print(model_output(h, fc_Weight, fc_Bias))\n",
    "\n",
    "print(f'np Hidden State: {h}')\n",
    "print(f'np Cell State: {c}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
